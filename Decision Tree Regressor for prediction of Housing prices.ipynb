{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression for House SalePrice prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries.\n",
    "Pandas will be used for reading data file and various other operations on the dataframe.\n",
    "Numpy will be used for mathematical operations on the data.\n",
    "sklearn.metrics and sklearn will be used for calculating accuracy and comparing the performance of the sklearn DecisionTreeRegressor with my own implementation of the same.\n",
    "math and random libraries will be used for various other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from the path and see the contents and columns and the datatypes.Check which values are null.Which of the columns are sparse and decide on the basis of this which columns to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 81 columns):\n",
      "Id               1000 non-null int64\n",
      "MSSubClass       1000 non-null int64\n",
      "MSZoning         1000 non-null object\n",
      "LotFrontage      825 non-null float64\n",
      "LotArea          1000 non-null int64\n",
      "Street           1000 non-null object\n",
      "Alley            50 non-null object\n",
      "LotShape         1000 non-null object\n",
      "LandContour      1000 non-null object\n",
      "Utilities        1000 non-null object\n",
      "LotConfig        1000 non-null object\n",
      "LandSlope        1000 non-null object\n",
      "Neighborhood     1000 non-null object\n",
      "Condition1       1000 non-null object\n",
      "Condition2       1000 non-null object\n",
      "BldgType         1000 non-null object\n",
      "HouseStyle       1000 non-null object\n",
      "OverallQual      1000 non-null int64\n",
      "OverallCond      1000 non-null int64\n",
      "YearBuilt        1000 non-null int64\n",
      "YearRemodAdd     1000 non-null int64\n",
      "RoofStyle        1000 non-null object\n",
      "RoofMatl         1000 non-null object\n",
      "Exterior1st      1000 non-null object\n",
      "Exterior2nd      1000 non-null object\n",
      "MasVnrType       993 non-null object\n",
      "MasVnrArea       993 non-null float64\n",
      "ExterQual        1000 non-null object\n",
      "ExterCond        1000 non-null object\n",
      "Foundation       1000 non-null object\n",
      "BsmtQual         970 non-null object\n",
      "BsmtCond         970 non-null object\n",
      "BsmtExposure     969 non-null object\n",
      "BsmtFinType1     970 non-null object\n",
      "BsmtFinSF1       1000 non-null int64\n",
      "BsmtFinType2     969 non-null object\n",
      "BsmtFinSF2       1000 non-null int64\n",
      "BsmtUnfSF        1000 non-null int64\n",
      "TotalBsmtSF      1000 non-null int64\n",
      "Heating          1000 non-null object\n",
      "HeatingQC        1000 non-null object\n",
      "CentralAir       1000 non-null object\n",
      "Electrical       999 non-null object\n",
      "1stFlrSF         1000 non-null int64\n",
      "2ndFlrSF         1000 non-null int64\n",
      "LowQualFinSF     1000 non-null int64\n",
      "GrLivArea        1000 non-null int64\n",
      "BsmtFullBath     1000 non-null int64\n",
      "BsmtHalfBath     1000 non-null int64\n",
      "FullBath         1000 non-null int64\n",
      "HalfBath         1000 non-null int64\n",
      "BedroomAbvGr     1000 non-null int64\n",
      "KitchenAbvGr     1000 non-null int64\n",
      "KitchenQual      1000 non-null object\n",
      "TotRmsAbvGrd     1000 non-null int64\n",
      "Functional       1000 non-null object\n",
      "Fireplaces       1000 non-null int64\n",
      "FireplaceQu      536 non-null object\n",
      "GarageType       947 non-null object\n",
      "GarageYrBlt      947 non-null float64\n",
      "GarageFinish     947 non-null object\n",
      "GarageCars       1000 non-null int64\n",
      "GarageArea       1000 non-null int64\n",
      "GarageQual       947 non-null object\n",
      "GarageCond       947 non-null object\n",
      "PavedDrive       1000 non-null object\n",
      "WoodDeckSF       1000 non-null int64\n",
      "OpenPorchSF      1000 non-null int64\n",
      "EnclosedPorch    1000 non-null int64\n",
      "3SsnPorch        1000 non-null int64\n",
      "ScreenPorch      1000 non-null int64\n",
      "PoolArea         1000 non-null int64\n",
      "PoolQC           6 non-null object\n",
      "Fence            192 non-null object\n",
      "MiscFeature      36 non-null object\n",
      "MiscVal          1000 non-null int64\n",
      "MoSold           1000 non-null int64\n",
      "YrSold           1000 non-null int64\n",
      "SaleType         1000 non-null object\n",
      "SaleCondition    1000 non-null object\n",
      "SalePrice        1000 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 632.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"train.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop very sparse columns i.e columns which have more than 80% of data as NA/NULL as they wont impact our model's performance significantly.Did some operations like renaming and replacing some values for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"Id\",\"Alley\",\"PoolQC\",\"MiscFeature\",\"Fence\",\"FireplaceQu\"],axis=1)\n",
    "df=df.rename(columns={\"SalePrice\":\"label\"})\n",
    "df[\"MSZoning\"].replace('C (all)', 'C',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nalist below contains the list/names of columns which contain the NA value.We observe which columns are sparse and which of them can be used through some imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nalist=df.columns[df.isna().any()].tolist()\n",
    "nalist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Data Imputation.Change the integer/continuous attributes with its mean and categorical attributes with the mode,and fill them back into the dataframe.And verify that there are no null values and unneccessary columns remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 75 columns):\n",
      "MSSubClass       1000 non-null int64\n",
      "MSZoning         1000 non-null object\n",
      "LotFrontage      1000 non-null float64\n",
      "LotArea          1000 non-null int64\n",
      "Street           1000 non-null object\n",
      "LotShape         1000 non-null object\n",
      "LandContour      1000 non-null object\n",
      "Utilities        1000 non-null object\n",
      "LotConfig        1000 non-null object\n",
      "LandSlope        1000 non-null object\n",
      "Neighborhood     1000 non-null object\n",
      "Condition1       1000 non-null object\n",
      "Condition2       1000 non-null object\n",
      "BldgType         1000 non-null object\n",
      "HouseStyle       1000 non-null object\n",
      "OverallQual      1000 non-null int64\n",
      "OverallCond      1000 non-null int64\n",
      "YearBuilt        1000 non-null int64\n",
      "YearRemodAdd     1000 non-null int64\n",
      "RoofStyle        1000 non-null object\n",
      "RoofMatl         1000 non-null object\n",
      "Exterior1st      1000 non-null object\n",
      "Exterior2nd      1000 non-null object\n",
      "MasVnrType       1000 non-null object\n",
      "MasVnrArea       1000 non-null float64\n",
      "ExterQual        1000 non-null object\n",
      "ExterCond        1000 non-null object\n",
      "Foundation       1000 non-null object\n",
      "BsmtQual         1000 non-null object\n",
      "BsmtCond         1000 non-null object\n",
      "BsmtExposure     1000 non-null object\n",
      "BsmtFinType1     1000 non-null object\n",
      "BsmtFinSF1       1000 non-null int64\n",
      "BsmtFinType2     1000 non-null object\n",
      "BsmtFinSF2       1000 non-null int64\n",
      "BsmtUnfSF        1000 non-null int64\n",
      "TotalBsmtSF      1000 non-null int64\n",
      "Heating          1000 non-null object\n",
      "HeatingQC        1000 non-null object\n",
      "CentralAir       1000 non-null object\n",
      "Electrical       1000 non-null object\n",
      "1stFlrSF         1000 non-null int64\n",
      "2ndFlrSF         1000 non-null int64\n",
      "LowQualFinSF     1000 non-null int64\n",
      "GrLivArea        1000 non-null int64\n",
      "BsmtFullBath     1000 non-null int64\n",
      "BsmtHalfBath     1000 non-null int64\n",
      "FullBath         1000 non-null int64\n",
      "HalfBath         1000 non-null int64\n",
      "BedroomAbvGr     1000 non-null int64\n",
      "KitchenAbvGr     1000 non-null int64\n",
      "KitchenQual      1000 non-null object\n",
      "TotRmsAbvGrd     1000 non-null int64\n",
      "Functional       1000 non-null object\n",
      "Fireplaces       1000 non-null int64\n",
      "GarageType       1000 non-null object\n",
      "GarageYrBlt      1000 non-null float64\n",
      "GarageFinish     1000 non-null object\n",
      "GarageCars       1000 non-null int64\n",
      "GarageArea       1000 non-null int64\n",
      "GarageQual       1000 non-null object\n",
      "GarageCond       1000 non-null object\n",
      "PavedDrive       1000 non-null object\n",
      "WoodDeckSF       1000 non-null int64\n",
      "OpenPorchSF      1000 non-null int64\n",
      "EnclosedPorch    1000 non-null int64\n",
      "3SsnPorch        1000 non-null int64\n",
      "ScreenPorch      1000 non-null int64\n",
      "PoolArea         1000 non-null int64\n",
      "MiscVal          1000 non-null int64\n",
      "MoSold           1000 non-null int64\n",
      "YrSold           1000 non-null int64\n",
      "SaleType         1000 non-null object\n",
      "SaleCondition    1000 non-null object\n",
      "label            1000 non-null int64\n",
      "dtypes: float64(3), int64(34), object(38)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "mean_frontage=df.LotFrontage.mean()\n",
    "mode_MasVnrType=df.MasVnrType.mode()[0]\n",
    "mean_MasVnrArea=df.MasVnrArea.mean()\n",
    "mode_BsmtQual=df.BsmtQual.mode()[0]\n",
    "mode_BsmtCond=df.BsmtCond.mode()[0]\n",
    "mode_BsmtExposure=df.BsmtExposure.mode()[0]\n",
    "mode_BsmtFinType1=df.BsmtFinType1.mode()[0]\n",
    "mode_BsmtFinType2=df.BsmtFinType2.mode()[0]\n",
    "mode_Electrical=df.Electrical.mode()[0]\n",
    "mode_GarageType=df.GarageType.mode()[0]\n",
    "mean_GarageYrBlt=df.GarageYrBlt.mean()\n",
    "mode_GarageFinish=df.GarageFinish.mode()[0]\n",
    "mode_GarageQual=df.GarageQual.mode()[0]\n",
    "mode_GarageCond=df.GarageCond.mode()[0]\n",
    "df=df.fillna({\"LotFrontage\":mean_frontage,\"MasVnrType\":mode_MasVnrType,\"MasVnrArea\":mean_MasVnrArea,\"BsmtQual\":mode_BsmtQual,\"BsmtCond\":mode_BsmtCond,\"BsmtExposure\":mode_BsmtExposure,\"BsmtFinType1\":mode_BsmtFinType1,\"BsmtFinType2\":mode_BsmtFinType2,\"Electrical\":mode_Electrical,\"GarageType\":mode_GarageType,\"GarageYrBlt\":mean_GarageYrBlt,\"GarageFinish\":mode_GarageFinish,\"GarageQual\":mode_GarageQual,\"GarageCond\":mode_GarageCond})\n",
    "global COLUMN_NAMES\n",
    "global TYPES_OF_FEATURES\n",
    "TYPES_OF_FEATURES=continuous_or_categorical(df)\n",
    "COLUMN_NAMES=df.columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>12099</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>13214</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>378500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>RM</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>4500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>FV</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>173733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>71.310303</td>\n",
       "      <td>6897</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6792</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>202665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>10625</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>71.310303</td>\n",
       "      <td>9101</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>13125</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>120500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0            60       RL    99.000000    12099   Pave      IR1         Lvl   \n",
       "1            20       RL    89.000000    13214   Pave      IR1         HLS   \n",
       "2           120       RM    32.000000     4500   Pave      Reg         Lvl   \n",
       "3           160       FV    30.000000     3000   Pave      Reg         Lvl   \n",
       "4            20       RL    71.310303     6897   Pave      IR1         Lvl   \n",
       "..          ...      ...          ...      ...    ...      ...         ...   \n",
       "995         120       RL    40.000000     6792   Pave      IR1         Lvl   \n",
       "996          30       RL    85.000000    10625   Pave      Reg         Lvl   \n",
       "997          85       RL    71.310303     9101   Pave      IR1         Lvl   \n",
       "998          20       RL    75.000000    13125   Pave      Reg         Lvl   \n",
       "999          20       RL    60.000000     9000   Pave      Reg         Lvl   \n",
       "\n",
       "    Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0      AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1      AllPub    Inside       Gtl  ...             0         0           0   \n",
       "2      AllPub       FR2       Gtl  ...             0         0           0   \n",
       "3      AllPub    Inside       Gtl  ...             0         0           0   \n",
       "4      AllPub    Corner       Gtl  ...             0         0           0   \n",
       "..        ...       ...       ...  ...           ...       ...         ...   \n",
       "995    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "996    AllPub    Corner       Gtl  ...            77         0           0   \n",
       "997    AllPub    Corner       Gtl  ...             0         0           0   \n",
       "998    AllPub    Inside       Mod  ...             0         0           0   \n",
       "999    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "    PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition   label  \n",
       "0          0       0       6    2007        WD         Normal  354000  \n",
       "1          0       0       5    2010        WD         Normal  378500  \n",
       "2          0       0       3    2006        WD         Normal  153500  \n",
       "3          0       0       6    2009       New        Partial  173733  \n",
       "4          0       0       4    2010        WD         Normal  127000  \n",
       "..       ...     ...     ...     ...       ...            ...     ...  \n",
       "995        0       0       3    2006       New        Partial  202665  \n",
       "996        0     400       5    2010       COD        Abnorml   83000  \n",
       "997        0       0       7    2009        WD         Normal  165500  \n",
       "998        0       0       4    2008        WD         Normal  208900  \n",
       "999        0       0       5    2007        WD         Normal  120500  \n",
       "\n",
       "[1000 rows x 75 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MSE returns the mean square error of the last column(here price).If there are no values present(there are no rows) then return mse as 0 else return the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(data):\n",
    "        if len(data[:,-1])==0:\n",
    "          mse=0\n",
    "        else:\n",
    "          #data[:-,1] is the last column which contains the labels of the price/value/label  \n",
    "          mse= np.mean((data[:,-1]-np.mean(data[:,-1]))**2)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall MSE basically calculates the weighted sum of mean squares of the left subtree and the right subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_mse(data_less_than,data_more_than):\n",
    "        n_data_points=len(data_less_than)+len(data_more_than)\n",
    "        #weights of both types of data\n",
    "        weighted_mse=((len(data_less_than)/n_data_points)*calculate_mse(data_less_than)+(len(data_more_than)/n_data_points)*calculate_mse(data_more_than))\n",
    "        return weighted_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find split positions gives the unique values for each column/attribute on which we can get a split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split_positions(data):\n",
    "    #will contain list of potentila  split values for that feature/column\n",
    "        split_positions={}\n",
    "        rows,num_of_columns=data.shape\n",
    "    #exclude the label column\n",
    "        for curr_column in range(num_of_columns-1):\n",
    "            values=data[:,curr_column]\n",
    "            unique_values=np.unique(values)\n",
    "            split_positions[curr_column]=unique_values\n",
    "        return split_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes dataframe as input and returns whether the column/feature is continuous or categorical in nature and returns a list saying the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine type of feature\n",
    "def continuous_or_categorical(df):\n",
    "        #to see the number of unique values in each type of feature\n",
    "        conti_or_categ=[]\n",
    "        #to see if a column contains a high value of categories\n",
    "        unique_values_threshold=15\n",
    "        for column in df.columns:\n",
    "            if column!=\"label\":\n",
    "                types=df[column].unique()\n",
    "                example_value=types[0]\n",
    "                if(isinstance(example_value,str)) or (len(types)<=unique_values_threshold):\n",
    "                    conti_or_categ.append(\"categorical\")\n",
    "                else:\n",
    "                    conti_or_categ.append(\"continuos\")    \n",
    "        return conti_or_categ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function divides the data on the basis of the given column name and the value corresponding to that column.If the split value is continuous then it uses >=,< condition else it uses ==,!= conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,split_column,split_value):\n",
    "    #now insetead of comparing features,we first find out if it is continuous or categorical\n",
    "    #if continuous we can compare with <= or >= if categorical we use ==\n",
    "        split_column_values=data[:,split_column]\n",
    "        type_of_feature=TYPES_OF_FEATURES[split_column]\n",
    "        if type_of_feature==\"continuous\":\n",
    "            data_less_than_split=data[split_column_values<=split_value]\n",
    "            data_more_than_split=data[split_column_values>split_value]\n",
    "        else:\n",
    "            data_less_than_split=data[split_column_values==split_value]\n",
    "            data_more_than_split=data[split_column_values!=split_value]\n",
    "        return data_less_than_split,data_more_than_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main Decision Tree Algorithm.We pass dataframe so that we dont need to pass train or test after converting to a 2-d array.This function takes min_samples to check if there are sufficient data points in that child and to avoid unneccesary splitting of the node.If less than min_samples,we can return the mean of the data.This way the height of the tree gets reduced and unncessary calculations/splits are avoided.We also pass the max-depth in our tree so that we dont keep on recursing and splitting the data even if we have sufficent depth and accuracy.This is called PRUNING of the tree \n",
    "\n",
    "The algo works as follows:\n",
    "It finds the possible splitting positions available for us from each attribute and stores them.\n",
    "Now for each column and each value of the column we check if the mean square error is the minimum mean square error until now or not.Which ever column and value gives the best(least)Mean square error after splitting becomes our splitting criteria for that node.\n",
    "Then we split the data on the basis of above values.\n",
    "Each node of our tree as the following format for continuous data {spliting critera <= satisfied: not_satisified} and for categorical data {spliting critera != satisfied: not_satisified} The 'satisfied' becomes the left child of the node and  'not satisfied' becomes the right child of the node.\n",
    "We call this recursively until we reach the leaf which happens when we reach the max depth or the number of rows,values are less than min samples.\n",
    "After reaching the leaf we simply return the mean of the remaining data present in that leaf.This will be our prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_decision_tree_algorithm(df,counter=0,min_samples=7,max_depth=5,first_iteration=True):\n",
    "        if first_iteration==True:\n",
    "            data=df.values\n",
    "        else:\n",
    "            data=df #called as 2-d array\n",
    "    \n",
    "        #basecase \n",
    "        if ((len(data)<min_samples) or (counter==max_depth)):\n",
    "            return np.mean(data[:,-1])\n",
    "\n",
    "        else:\n",
    "            counter+=1\n",
    "            first_iteration=False\n",
    "            split_positions=find_split_positions(data)\n",
    "       \n",
    "        #finding the split which gives the least mean square error\n",
    "        best_mse=999999999999999999999999999\n",
    "        for column_index in split_positions:\n",
    "            for value in split_positions[column_index]:\n",
    "                data_less_than,data_more_than=split_data(data,column_index,value)\n",
    "                current_mse=calculate_overall_mse(data_less_than,data_more_than)\n",
    "                if (current_mse <= best_mse):\n",
    "                        best_mse=current_mse\n",
    "                        split_column=column_index\n",
    "                        split_value=value\n",
    "        data_less_than,data_more_than=split_data(data,split_column,split_value)\n",
    "        \n",
    "        #checkforemptyclass\n",
    "        if len(data_less_than)==0 or len(data_more_than)==0:\n",
    "            return np.mean(data[:-1])\n",
    "        \n",
    "        #instantiate subtree (recurse) tells the column name where split\n",
    "        #to get only the inndex use split_column in .format()\n",
    "        feature_name=COLUMN_NAMES[split_column]\n",
    "        type_of_feature=TYPES_OF_FEATURES[split_column]\n",
    "        if type_of_feature==\"continuous\":\n",
    "            criteria=\"{} <= {}\".format(feature_name,split_value)\n",
    "        else:\n",
    "            criteria=\"{} == {}\".format(feature_name,split_value)\n",
    "        \n",
    "        tree_node={criteria: []}\n",
    "        \n",
    "        #find_subtree_answers\n",
    "        left_subtree_condn=opt_decision_tree_algorithm(data_less_than,counter,min_samples,max_depth,first_iteration)\n",
    "        right_subtree_condn=opt_decision_tree_algorithm(data_more_than,counter,min_samples,max_depth,first_iteration)\n",
    "        \n",
    "        #append only the name if not splitting\n",
    "        if left_subtree_condn==right_subtree_condn:\n",
    "            tree_node=right_subtree_condn\n",
    "        else:\n",
    "            tree_node[criteria].append(left_subtree_condn)\n",
    "            tree_node[criteria].append(right_subtree_condn)\n",
    "\n",
    "        return tree_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used for traversing along the constructed decsion tree frome above function.This matches the corresponding attributes and checks the conditions mentioned in the nodes until it reaches a leaf,at which point the mean of the data points present in leaf is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision(decision_tree,criteria,value,operator,feature,df_row):\n",
    "        if(operator==\"<=\"):\n",
    "            value=float(value)\n",
    "                    #ask question\n",
    "            if df_row[feature]<=value:\n",
    "                trueorfalse=decision_tree[criteria][0]\n",
    "            else:\n",
    "                trueorfalse=decision_tree[criteria][1]\n",
    "                        #the value can be a integer or a string\n",
    "        elif(operator!=\"<=\"):\n",
    "            if str(df_row[feature])==value:\n",
    "                trueorfalse=decision_tree[criteria][0]\n",
    "            else:\n",
    "                trueorfalse=decision_tree[criteria][1]\n",
    "        return trueorfalse        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example(df_row,decision_tree):\n",
    "         #get the splitting_criteria(key)\n",
    "        criteria=list(decision_tree.keys())[0]\n",
    "        #get the answers(elements of the string)\n",
    "        feature,operator,value=criteria.split(\" \")\n",
    "        #ask question\n",
    "        trueorfalse=get_decision(decision_tree,criteria,value,operator,feature,df_row)\n",
    "        if not isinstance(trueorfalse,dict):\n",
    "            return trueorfalse\n",
    "        else:\n",
    "            sub_tree=trueorfalse\n",
    "            return predict_example(df_row,sub_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below splits the data into training data and testing data in two parts as per the size passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "def train_test_split(df,test_size):\n",
    "    df_size=len(df)\n",
    "    if isinstance(test_size,float):#if test size is passed as a proportion\n",
    "        test_size=round(test_size*df_size)\n",
    "    #pick random samples from the data for train test split\n",
    "    indexes=df.index.tolist()\n",
    "    test_indices=random.sample(population=indexes,k=test_size)\n",
    "    #now putting the values of train and test data into the respective df's\n",
    "    test_df=df.loc[test_indices]\n",
    "    cropped_df=df.drop(test_indices)\n",
    "    train_df=cropped_df\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the  original data into train and validation data.We keep the training size 75% and validation size 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,val_df=train_test_split(df,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to obtain the optimal value of maximum depth and minimum samples we perform cross validation.The split which gives best train and cross validation score will be our final hyperparameters for test data.We use the R-square test to evaluate our model.Any model which gives R-square score >=0.5 is considered to be a good mode,however improvements are still possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  5\n",
      "current_min_samples :  5\n",
      "current_training score :  0.8309028033232058\n",
      "current_validation score :  0.6758061502894412\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  5\n",
      "current_min_samples :  9\n",
      "current_training score :  0.8167488769423007\n",
      "current_validation score :  0.6730130810879402\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  5\n",
      "current_min_samples :  13\n",
      "current_training score :  0.770109614234409\n",
      "current_validation score :  0.7234010069821236\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  5\n",
      "current_min_samples :  17\n",
      "current_training score :  0.770109614234409\n",
      "current_validation score :  0.7234010069821236\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  6\n",
      "current_min_samples :  5\n",
      "current_training score :  0.8737307488174215\n",
      "current_validation score :  0.694905523919686\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  6\n",
      "current_min_samples :  9\n",
      "current_training score :  0.8576193839116241\n",
      "current_validation score :  0.6922754174310086\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  6\n",
      "current_min_samples :  13\n",
      "current_training score :  0.8070268811845511\n",
      "current_validation score :  0.7430111967103633\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  6\n",
      "current_min_samples :  17\n",
      "current_training score :  0.8003137854358094\n",
      "current_validation score :  0.7370202737937858\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  7\n",
      "current_min_samples :  5\n",
      "current_training score :  0.9015279215166524\n",
      "current_validation score :  0.7184397761272763\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  7\n",
      "current_min_samples :  9\n",
      "current_training score :  0.8797565910558108\n",
      "current_validation score :  0.7112556519772038\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  7\n",
      "current_min_samples :  13\n",
      "current_training score :  0.8266890744606028\n",
      "current_validation score :  0.7643742278698118\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  7\n",
      "current_min_samples :  17\n",
      "current_training score :  0.8187430396111848\n",
      "current_validation score :  0.7588081930767065\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  8\n",
      "current_min_samples :  5\n",
      "current_training score :  0.9268309698993407\n",
      "current_validation score :  0.7082840076209908\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  8\n",
      "current_min_samples :  9\n",
      "current_training score :  0.9024313633737028\n",
      "current_validation score :  0.7047307002524552\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  8\n",
      "current_min_samples :  13\n",
      "current_training score :  0.8482725482939204\n",
      "current_validation score :  0.7560243571246533\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  8\n",
      "current_min_samples :  17\n",
      "current_training score :  0.8385929632138064\n",
      "current_validation score :  0.7517342790865161\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  9\n",
      "current_min_samples :  5\n",
      "current_training score :  0.9404917589879902\n",
      "current_validation score :  0.702803696197257\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  9\n",
      "current_min_samples :  9\n",
      "current_training score :  0.9149099466727172\n",
      "current_validation score :  0.6994442503166305\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  9\n",
      "current_min_samples :  13\n",
      "current_training score :  0.8595286383397176\n",
      "current_validation score :  0.7529833504146735\n",
      "-----------------------------------------------------------------------\n",
      "current_max_depth :  9\n",
      "current_min_samples :  17\n",
      "current_training score :  0.8476524834054872\n",
      "current_validation score :  0.7521367730585246\n"
     ]
    }
   ],
   "source": [
    "best_validation_score=0\n",
    "best_training_score=0\n",
    "best_max_depth=0\n",
    "best_min_samples=0\n",
    "train_labels=train_df.label\n",
    "val_labels=val_df.label\n",
    "train_labels=train_labels.to_numpy()\n",
    "val_labels=val_labels.to_numpy()\n",
    "for max_depth in range(5,10):\n",
    "    for min_samples in range(5,20,4):\n",
    "        current_tree=opt_decision_tree_algorithm(train_df,max_depth=max_depth, min_samples=min_samples,first_iteration=True)\n",
    "        train_predictions=train_df.apply(predict_example, args=(current_tree,), axis=1)\n",
    "        val_predictions=val_df.apply(predict_example, args=(current_tree,), axis=1)\n",
    "        curr_train_score=(r2_score(train_labels, train_predictions.to_numpy()))\n",
    "        curr_val_score=(r2_score(val_labels, val_predictions.to_numpy()))\n",
    "        print('-----------------------------------------------------------------------')\n",
    "        if(curr_train_score >= best_training_score or curr_val_score>=best_validation_score):\n",
    "            print(\"current_max_depth : \",max_depth)\n",
    "            print(\"current_min_samples : \",min_samples)\n",
    "            print(\"current_training score : \",curr_train_score)\n",
    "            print(\"current_validation score : \",curr_val_score)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Above we see that after some trade off between the two scores,we can choose our hyperparameters as max_depth=8\n",
    "and min_samples=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test our data with the above hyperparameters we got from cross-validation.We perfrom  similar changes to test data as we did initially to fit our model's needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"test.csv\")\n",
    "df_labels=pd.read_csv(\"test_labels.csv\")\n",
    "df_test=df_test.join(df_labels,lsuffix='_test', rsuffix='_labels')\n",
    "df_test=df_test.rename(columns={\"Labels\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop([\"Id_test\",\"Alley\",\"PoolQC\",\"MiscFeature\",\"Fence\",\"FireplaceQu\",\"Id_labels\"],axis=1)\n",
    "tmean_frontage=df_test.LotFrontage.mean()\n",
    "tmode_MasVnrType=df_test.MasVnrType.mode()[0]\n",
    "tmean_MasVnrArea=df_test.MasVnrArea.mean()\n",
    "tmode_BsmtQual=df_test.BsmtQual.mode()[0]\n",
    "tmode_BsmtCond=df_test.BsmtCond.mode()[0]\n",
    "tmode_BsmtExposure=df_test.BsmtExposure.mode()[0]\n",
    "tmode_BsmtFinType1=df_test.BsmtFinType1.mode()[0]\n",
    "tmode_BsmtFinType2=df_test.BsmtFinType2.mode()[0]\n",
    "tmode_GarageType=df_test.GarageType.mode()[0]\n",
    "tmean_GarageYrBlt=df_test.GarageYrBlt.mean()\n",
    "tmode_GarageFinish=df_test.GarageFinish.mode()[0]\n",
    "tmode_GarageQual=df_test.GarageQual.mode()[0]\n",
    "tmode_GarageCond=df_test.GarageCond.mode()[0]\n",
    "df_test[\"MSZoning\"].replace('C (all)', 'C', inplace=True)\n",
    "\n",
    "df_test=df_test.fillna({\"LotFrontage\":tmean_frontage,\"MasVnrType\":tmode_MasVnrType,\"MasVnrArea\":tmean_MasVnrArea,\"BsmtQual\":tmode_BsmtQual,\"BsmtCond\":tmode_BsmtCond,\"BsmtExposure\":tmode_BsmtExposure,\"BsmtFinType1\":tmode_BsmtFinType1,\"BsmtFinType2\":tmode_BsmtFinType2,\"GarageType\":tmode_GarageType,\"GarageYrBlt\":tmean_GarageYrBlt,\"GarageFinish\":tmode_GarageFinish,\"GarageQual\":tmode_GarageQual,\"GarageCond\":tmode_GarageCond})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose and train the model on the depth and min_samples we got from validation and run it on our test data and then we calculate the R-square score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6810709806675279\n"
     ]
    }
   ],
   "source": [
    "best_max_depth=8\n",
    "best_min_samples=9\n",
    "\n",
    "test_tree=opt_decision_tree_algorithm(train_df,max_depth=best_max_depth, min_samples=best_min_samples,first_iteration=True)\n",
    "\n",
    "test_predictions=df_test.apply(predict_example, args=(test_tree,), axis=1)\n",
    "\n",
    "test_labels=df_test.label\n",
    "test_labels=test_labels.to_numpy()\n",
    "\n",
    "test_score=(r2_score(test_labels, test_predictions.to_numpy()))\n",
    "\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.R-square test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also called co-efficient of determination.R-squared is a statistical measure of how close the data are to the fitted regression line.\n",
    "The definition of R-squared is fairly straight-forward; it is the percentage of the response variable variation that is explained by a linear model.\n",
    "R-squared = Explained variation / Total variation\n",
    "R-squared is always between 0 and 100%:\n",
    "0% indicates that the model explains none of the variability of the response data around its mean.\n",
    "100% indicates that the model explains all the variability of the response data around its mean.\n",
    "In general, the higher the R-squared, the better the model fits your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6810709806675279\n"
     ]
    }
   ],
   "source": [
    "rsq_score=(r2_score(test_labels, test_predictions.to_numpy()))\n",
    "print(rsq_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errorsâ€”that is, the average squared difference between the estimated values and the actual value. MSE is a risk function, corresponding to the expected value of the squared error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1685477686.6229556\n"
     ]
    }
   ],
   "source": [
    "mse_score=mean_squared_error(test_labels, test_predictions.to_numpy())\n",
    "print(mse_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE) is the average vertical distance between each point and the identity line. MAE is also the average horizontal distance between each point and the identity line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28763.08254462236\n"
     ]
    }
   ],
   "source": [
    "mae_score=mean_absolute_error(test_labels, test_predictions.to_numpy())\n",
    "print(mae_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Simple Mean Model (SMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple mean model like its name simply returns the mean of all the data which the classifier has seen.The deviation of this mean from the real values in the test data will establish a baseline score for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score :  -0.005159083984031421\n",
      "Mean Square Error  :  5312069786.272223\n",
      "Mean Absolute Error  :  54421.37277101448\n"
     ]
    }
   ],
   "source": [
    "smm_predictions=[]\n",
    "train_mean=np.mean(train_labels)\n",
    "for i in range(test_labels.shape[0]):\n",
    "    smm_predictions.append(train_mean)\n",
    "smm_predictions=np.array(smm_predictions)\n",
    "print(\"R-squared score : \",r2_score(test_labels,smm_predictions))\n",
    "print(\"Mean Square Error  : \",mean_squared_error(test_labels,smm_predictions))\n",
    "print(\"Mean Absolute Error  : \",mean_absolute_error(test_labels,smm_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
